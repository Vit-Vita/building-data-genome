{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FaDPurFCNr9"
   },
   "source": [
    "# Building Data Genome - Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehj5cAp_cAwp"
   },
   "source": [
    "## Installations and Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YsvFPgNO-ITm"
   },
   "outputs": [],
   "source": [
    "#Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "jiiRW4335E5W"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as pylab\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use working directory in Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#!pwd\n",
    "#!ls '/content/drive/MyDrive/Colab Notebooks/Energy Systems/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use local directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z-6V3NB-SpI4"
   },
   "outputs": [],
   "source": [
    "#Import csv data into dataframes\n",
    "\n",
    "#file path:\n",
    "file_path = 'D:/building-data-genome/project_data/'\n",
    "\n",
    "#Energy related\n",
    "df_solar = pd.read_csv(file_path + 'solar_cleaned.csv')\n",
    "df_water = pd.read_csv(file_path + 'water_cleaned.csv')\n",
    "df_electricity = pd.read_csv(file_path + 'electricity_cleaned.csv')\n",
    "df_gas = pd.read_csv(file_path + 'gas_cleaned.csv')\n",
    "df_hotwater = pd.read_csv(file_path + 'hotwater_cleaned.csv')\n",
    "df_irrigation = pd.read_csv(file_path + 'irrigation_cleaned.csv')\n",
    "df_chilledwater = pd.read_csv(file_path + 'chilledwater_cleaned.csv')\n",
    "df_steam = pd.read_csv(file_path + 'steam_cleaned.csv')\n",
    "\n",
    "#Metadata\n",
    "df_metadata = pd.read_csv(file_path + 'metadata.csv')\n",
    "\n",
    "#Weather\n",
    "df_weather = pd.read_csv(file_path + 'weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2VG1rSR8mmFV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.33 Mb (18.9% reduction)\n",
      "Mem. usage decreased to 1838.90 Mb (10.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Keep only buildings of the top 5 regions in our dataset:\n",
    "df_metadata = df_metadata[df_metadata[\"timezone\"].isin([\"US/Eastern\", \"US/Central\", \"Europe/London\", \"US/Mountain\", \"US/Pacific\"])]\n",
    "\n",
    "\n",
    "# Reformat the meters dataframes first\n",
    "\n",
    "def melt_meter_dataframes (df, meter_name):\n",
    "  #timestamp into datetime\n",
    "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "  # Melt the DataFrame: columns become rows under 'building_id', and their values go under 'meter_reading'\n",
    "  df = df.melt(\n",
    "      id_vars=[\"timestamp\"],              # Columns to keep as is\n",
    "      var_name=\"building_id\",             # Name for the new column with former column names\n",
    "      value_name=\"meter_reading\"          # Name for the new column with values from the original DataFrame\n",
    "      )\n",
    "\n",
    "  # Add the 'meter' column\n",
    "  df[\"meter\"] = meter_name\n",
    "\n",
    "  # Rearrange columns for clarity\n",
    "  df = df[[\"timestamp\", \"building_id\", \"meter\", \"meter_reading\"]]\n",
    "\n",
    "  return df\n",
    "\n",
    "df_electricity = melt_meter_dataframes(df_electricity, \"electricity\")\n",
    "df_gas = melt_meter_dataframes(df_gas, \"gas\")\n",
    "df_hotwater = melt_meter_dataframes(df_hotwater, \"hotwater\")\n",
    "df_chilledwater = melt_meter_dataframes(df_chilledwater, \"chilledwater\")\n",
    "df_steam = melt_meter_dataframes(df_steam, \"steam\")\n",
    "df_water = melt_meter_dataframes(df_water, \"water\")\n",
    "df_irrigation = melt_meter_dataframes(df_irrigation, \"irrigation\")\n",
    "df_solar = melt_meter_dataframes(df_solar, \"solar\")\n",
    "\n",
    "\n",
    "# Function to reduce the DF size ( https://www.kaggle.com/caesarlupum/ashrae-start-here-a-gentle-introduction)\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "# Reduce memory\n",
    "df_metadata = reduce_mem_usage(df_metadata)\n",
    "gc.collect()\n",
    "\n",
    "# Concatenate all meters data and then merge it with metadata\n",
    "\n",
    "# Concatenate all the meter dataframes\n",
    "meters = pd.concat([df_electricity, df_gas, df_hotwater, df_chilledwater, df_steam, df_water, df_irrigation, df_solar])\n",
    "meters = reduce_mem_usage(meters)\n",
    "gc.collect()\n",
    "\n",
    "# Features from buildings metadata to add to meters dataset\n",
    "buildings_sel = df_metadata[[\"building_id\",\"site_id\",\"primaryspaceusage\",\"timezone\"]]\n",
    "\n",
    "# Join the datasets: meter reading + building metadata\n",
    "dev = meters.merge(buildings_sel, on=\"building_id\", how = \"left\")\n",
    "\n",
    "# Transform timestamp to datetime object type\n",
    "dev[\"timestamp\"] = pd.to_datetime(dev[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "del(meters, buildings_sel, df_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'building_id', 'meter', 'meter_reading', 'site_id',\n",
       "       'primaryspaceusage', 'timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had concluded in our exploratory data analysis that there are differences across regions in these cases:\n",
    "\n",
    "1) For yearly load profiles per usage type\n",
    "2) For certain daily load profiles per usage type\n",
    "3) For certain daily load profiles per meter type \n",
    "\n",
    "We will try to see if we can effectively classify the types of buildings per their load profiles as found in each region on a yearly basis and on a daily basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
